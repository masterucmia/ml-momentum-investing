# ETL-Databricks ‚Äì Pipeline de Datos Financieros (Bronze / Silver / Gold)

## √çndice

1. [Arquitectura General](#-arquitectura-general)
2. [Bronze ‚Äì Ingesta de Datos OHLCV en Tiempo Casi Real](#-bronze--ingesta-de-datos-ohlcv-en-tiempo-casi-real)
   - [Objetivo de la Capa Bronze](#-objetivo-de-la-capa-bronze)
   - [Origen de los Datos](#-origen-de-los-datos)
   - [Universos de Activos Ingeridos](#-universos-de-activos-ingeridos)
   - [Modelo de Ingesta](#-modelo-de-ingesta)
   - [Gesti√≥n Temporal y Zonas Horarias](#-gesti√≥n-temporal-y-zonas-horarias)
   - [Estructura y Almacenamiento en Bronze](#-estructura-y-almacenamiento-en-bronze)
   - [Resultado de la Capa Bronze](#-resultado-de-la-capa-bronze)
3. [Silver ‚Äì Normalizaci√≥n y Enriquecimiento OHLCV 1m](#-silver--normalizaci√≥n-y-enriquecimiento-ohlcv-1m-streaming-stateful)
   - [Objetivo de la Capa Silver](#-objetivo-de-la-capa-silver)
   - [Origen de los Datos](#-origen-de-los-datos-1)
   - [Modelo de Procesamiento](#-modelo-de-procesamiento)
   - [Limpieza y Validaciones Aplicadas](#-limpieza-y-validaciones-aplicadas)
   - [Normalizaci√≥n Temporal](#-normalizaci√≥n-temporal)
   - [Normalizaci√≥n de Identificadores](#-normalizaci√≥n-de-identificadores)
   - [Enriquecimiento con Dimensi√≥n de Activos](#-enriquecimiento-con-dimensi√≥n-de-activos)
   - [L√≥gica de Negocio Introducida](#-l√≥gica-de-negocio-introducida)
   - [Resultado de la Capa Silver](#-resultado-de-la-capa-silver)
4. [Gold ‚Äì Dataset Anal√≠tico ML-Ready](#-gold--dataset-anal√≠tico-ml-ready-streaming)
   - [Objetivo de la Capa Gold](#-objetivo-de-la-capa-gold)
   - [Origen de los Datos](#-origen-de-los-datos-2)
   - [Modelo de Procesamiento](#-modelo-de-procesamiento-1)
   - [Validaciones Finales](#-validaciones-finales)
   - [Selecci√≥n de Variables](#-selecci√≥n-de-variables-feature-selection)
   - [Normalizaci√≥n Temporal](#-normalizaci√≥n-temporal-1)
   - [Resultado de la Capa Gold](#-resultado-de-la-capa-gold)

---

Este directorio contiene los notebooks de **ETL ejecutados en Databricks** que implementan un pipeline completo de **ingesta, transformaci√≥n y consolidaci√≥n de datos financieros**, siguiendo una arquitectura **Lakehouse basada en capas Bronze, Silver y Gold**.

El pipeline est√° dise√±ado para trabajar con **series temporales financieras de alta frecuencia (1 minuto)** y cubrir m√∫ltiples clases de activos (acciones, ETFs, divisas, criptomonedas y commodities).

---

## Arquitectura General

El flujo de datos sigue el patr√≥n cl√°sico de Lakehouse:

1. **Bronze** ‚Äì Ingesta cruda desde la fuente externa
2. **Silver** ‚Äì Limpieza, validaci√≥n y normalizaci√≥n _(pendiente de documentar)_
3. **Gold** ‚Äì Construcci√≥n de datasets anal√≠ticos finales _(pendiente de documentar)_

Cada capa tiene una responsabilidad clara y desacoplada, lo que permite reprocesos controlados y trazabilidad completa del dato.

---

## Bronze ‚Äì Ingesta de Datos OHLCV en Tiempo Casi Real

### Objetivo de la Capa Bronze

La capa **Bronze** es responsable de la **ingesta directa de datos financieros OHLCV** (_Open, High, Low, Close, Volume_) a **frecuencia de 1 minuto**, preservando el dato original con transformaciones m√≠nimas.

Su finalidad es:

- Capturar el dato tal como lo expone la fuente externa
- Garantizar trazabilidad temporal
- Servir como base inmutable para las capas Silver y Gold

---

### Origen de los Datos

Los datos se obtienen desde la librer√≠a **Yahoo Finance**, utilizando su interfaz program√°tica para descarga de series temporales.

Caracter√≠sticas del origen:

- Datos financieros p√∫blicos
- Resoluci√≥n: **1 minuto**
- Periodo consultado: **d√≠a en curso**
- Activos de m√∫ltiples mercados y clases

La ingesta se ejecuta desde Databricks, que act√∫a como motor de procesamiento y orquestaci√≥n.

---

### Universos de Activos Ingeridos

El pipeline Bronze cubre un universo amplio y diversificado de activos, organizado en grupos l√≥gicos:

- **Acciones (S&P 500 y grandes compa√±√≠as)**
- **Fondos cotizados (ETFs)**
- **Divisas (Forex)**
- **Criptomonedas**
- **Commodities (v√≠a ETFs)**

Cada activo se identifica de forma expl√≠cita por su s√≠mbolo de mercado, y se procesa de manera independiente para garantizar robustez ante fallos parciales.

---

### Modelo de Ingesta

La ingesta sigue un modelo de **polling continuo**, con las siguientes caracter√≠sticas:

- Ejecuci√≥n c√≠clica cada **60 segundos**
- Descarga √∫nicamente de **velas cerradas**
- Procesamiento incremental dentro del d√≠a
- Control de √∫ltimo timestamp ingerido por activo

Este enfoque evita duplicidades y garantiza que solo se persistan nuevos datos.

---

### Gesti√≥n Temporal y Zonas Horarias

- Los timestamps se normalizan a **UTC**.
- Se conserva informaci√≥n expl√≠cita de la zona horaria l√≥gica del mercado.
- Se a√±aden campos temporales derivados para facilitar particionado y consultas posteriores.

Esto permite:

- Comparar activos de distintos mercados
- Evitar ambig√ºedades temporales
- Optimizar el almacenamiento en el Data Lake

---

### Estructura y Almacenamiento en Bronze

Los datos se almacenan en el **Data Lake** utilizando el formato **Delta Lake**, con las siguientes caracter√≠sticas:

- Escritura en modo _append_
- Particionado por:
  - A√±o
  - Mes
  - D√≠a
- Estructura orientada a series temporales

Cada registro contiene, entre otros:

- Timestamp de la vela
- S√≠mbolo del activo
- Valores OHLC
- Volumen
- Fuente del dato
- Metadatos temporales

---

### Resultado de la Capa Bronze

El resultado es un dataset:

- Crudo y fiel al origen
- No agregado
- No enriquecido
- Optimizado para reprocesado y auditor√≠a

La capa Bronze **no est√° pensada para an√°lisis directo**, sino como base s√≥lida para las siguientes capas.

---

### Consideraciones Importantes

- No se aplican reglas de negocio
- No se eliminan outliers
- No se realizan agregaciones
- Cualquier correcci√≥n o interpretaci√≥n se delega a Silver y Gold

---

_La capa Bronze garantiza la captura fiable y trazable del dato financiero en alta frecuencia, sirviendo como pilar del resto del pipeline._

## Silver ‚Äì Normalizaci√≥n y Enriquecimiento OHLCV 1m (Streaming Stateful)

### Objetivo de la Capa Silver

La capa **Silver** es responsable de **procesar en streaming los datos OHLCV de 1 minuto provenientes de Bronze**, aplicando **limpieza, normalizaci√≥n temporal y enriquecimiento sem√°ntico**, para producir un dataset **consistente y listo para an√°lisis**.

A diferencia de Bronze, esta capa **s√≠ introduce l√≥gica de negocio controlada**, manteniendo siempre la trazabilidad del dato original.

---

### Origen de los Datos

- Lectura en **streaming** desde la **capa Bronze**, almacenada en formato **Delta Lake**.
- El stream consume de forma incremental los nuevos registros que se van incorporando a Bronze.
- Se ignoran eliminaciones para garantizar un modelo append-only coherente con ingesta hist√≥rica.

Silver act√∫a como **consumidor continuo** del lago Bronze.

---

### Modelo de Procesamiento

El procesamiento se implementa mediante un **modelo de streaming stateful con `foreachBatch`**, lo que permite:

- Tratar cada micro-lote como un DataFrame independiente
- Aplicar l√≥gica compleja de limpieza y enriquecimiento
- Mantener control expl√≠cito de errores y escritura

El estado del stream se gestiona mediante **checkpoints**, garantizando:

- Reanudaci√≥n segura ante fallos
- Procesamiento exactamente-una-vez
- Consistencia entre ejecuciones

---

### Limpieza y Validaciones Aplicadas

En cada batch, Silver aplica una serie de validaciones y filtros estrictos:

- Eliminaci√≥n de duplicados por combinaci√≥n **(s√≠mbolo, timestamp)**.
- Descarte de registros incompletos:
  - Timestamps nulos
  - Precios de cierre nulos
  - S√≠mbolos no informados
  - Fuente de datos no identificada

Estas reglas garantizan que el dataset Silver **no contenga datos corruptos o ambiguos**.

---

### Normalizaci√≥n Temporal

- Todos los timestamps se convierten desde **UTC** a la zona horaria **Europe/Madrid**.
- Se mantiene coherencia temporal entre activos de distintos mercados.
- Se preservan los campos derivados de partici√≥n temporal (a√±o, mes, d√≠a).

Esto facilita:

- An√°lisis intrad√≠a
- Backtesting coherente
- Comparaci√≥n entre activos heterog√©neos

---

### Normalizaci√≥n de Identificadores

- Los s√≠mbolos de mercado se normalizan para eliminar sufijos t√©cnicos del origen.
- Se garantiza una **identidad √∫nica y consistente por activo**, independientemente de su procedencia.

---

### Enriquecimiento con Dimensi√≥n de Activos

Silver introduce una **dimensi√≥n de activos** mantenida internamente, que permite enriquecer cada registro con informaci√≥n sem√°ntica:

- Clase de activo (Acciones, Fondos, Forex, Cripto, Commodities)
- Nombre descriptivo del activo
- Coste operativo horario asociado a la clase de activo

Este enriquecimiento se realiza mediante una uni√≥n controlada, manteniendo el car√°cter determinista del pipeline.

---

### L√≥gica de Negocio Introducida

En esta capa se a√±aden **atributos econ√≥micos b√°sicos**, como:

- Coste operativo por hora, dependiente del tipo de activo
- Clasificaci√≥n por familia financiera

Estas variables ser√°n utilizadas posteriormente en:

- C√°lculo de rentabilidades netas
- Simulaci√≥n de estrategias
- Modelos de decisi√≥n

Silver **no calcula m√©tricas financieras complejas**, sino que prepara el terreno para Gold.

---

### Escritura y Almacenamiento

Los datos procesados se almacenan en la **capa Silver** con las siguientes caracter√≠sticas:

- Formato: **Delta Lake**
- Modo de escritura: _append_
- Particionado por:
  - A√±o
  - Mes
  - D√≠a
- Dataset optimizado para lectura anal√≠tica y reprocesos

---

### Resultado de la Capa Silver

El resultado es un dataset:

- Limpio y sin duplicados
- Temporalmente coherente
- Enriquecido con contexto financiero
- Apto para an√°lisis y modelado

Silver act√∫a como **fuente √∫nica de verdad intermedia** para la capa Gold.

---

### Consideraciones Importantes

- Silver depende completamente de Bronze.
- Cualquier cambio en reglas de limpieza o enriquecimiento requiere reprocesar Silver y Gold.
- Silver no debe usarse para ingesta ni reprocesado de capas anteriores.

---

üìå _La capa Silver transforma datos crudos en informaci√≥n financiera consistente, manteniendo un equilibrio entre fidelidad al origen y preparaci√≥n anal√≠tica._

## Gold ‚Äì Dataset Anal√≠tico ML-Ready (Streaming)

### Objetivo de la Capa Gold

La capa **Gold** es responsable de construir el **dataset final orientado a an√°lisis cuantitativo y modelos de Machine Learning**, partiendo de los datos ya limpios y enriquecidos en Silver.

Esta capa define la **vista can√≥nica de los datos financieros** que ser√° utilizada para:

- Backtesting de estrategias
- An√°lisis estad√≠stico
- Entrenamiento de modelos de ML

Gold prioriza **simplicidad, consistencia y estabilidad del esquema**.

---

### üîå Origen de los Datos

- Lectura en **streaming** desde la **capa Silver**, en formato **Delta Lake**.
- Consumo incremental de nuevos registros conforme Silver los va generando.
- Modelo _append-only_, coherente con ingesta hist√≥rica y reprocesos.

Gold act√∫a como **consumidor final del pipeline de datos**.

---

### Modelo de Procesamiento

El procesamiento se realiza mediante un **streaming controlado con `foreachBatch`**, lo que permite:

- Tratar cada micro-lote de forma determinista
- Aplicar validaciones finales de calidad
- Mantener control sobre escritura y errores

El uso de **checkpoints** garantiza:

- Reanudaci√≥n autom√°tica tras fallos
- Procesamiento exactamente-una-vez
- Integridad del dataset final

---

### Validaciones Finales

Antes de persistir los datos en Gold, se aplican validaciones estrictas:

- Eliminaci√≥n de registros sin timestamp v√°lido
- Descarte de registros sin s√≠mbolo de activo
- Eliminaci√≥n de registros sin precio de cierre
- Garant√≠a de existencia de coste operativo

Estas validaciones aseguran que **Gold solo contenga observaciones completas y utilizables**.

---

### Selecci√≥n de Variables (Feature Selection)

Gold define expl√≠citamente el **conjunto m√≠nimo de variables necesarias para an√°lisis y ML**, evitando ruido innecesario:

- Informaci√≥n temporal (timestamp)
- Identidad del activo
- Clasificaci√≥n del activo
- Coste operativo
- Precio de cierre

No se incluyen campos t√©cnicos ni metadatos intermedios.

---

### Normalizaci√≥n Temporal

- Los timestamps se gestionan en la zona horaria **Europe/Madrid**.
- Se derivan expl√≠citamente los campos:
  - A√±o
  - Mes
  - D√≠a

Esto facilita:

- Particionado eficiente
- Ventanas temporales
- Agregaciones y resampling posteriores

---

### Escritura y Almacenamiento

Los datos se almacenan en la **capa Gold** con las siguientes caracter√≠sticas:

- Formato: **Delta Lake**
- Modo de escritura: _append_
- Particionado por:
  - A√±o
  - Mes
  - D√≠a
- Esquema estable y orientado a consumo anal√≠tico

La capa Gold est√° optimizada para:

- Lectura intensiva
- Procesos de modelado
- Reproducibilidad de experimentos

---

### Resultado de la Capa Gold

El resultado es un dataset:

- Consistente y sin valores faltantes cr√≠ticos
- Normalizado y estructurado
- Directamente utilizable por modelos de ML
- Independiente de la l√≥gica de ingesta

Gold representa la **fuente √∫nica de verdad anal√≠tica** del sistema.

---

### Consideraciones Importantes

- Gold depende completamente de Silver.
- Cambios en el esquema de Gold deben justificarse anal√≠ticamente.
- Gold no debe usarse como fuente para reprocesar capas anteriores.

---

_La capa Gold materializa el dato financiero en su forma final, preparada para an√°lisis cuantitativo y aprendizaje autom√°tico._
