{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d936cde-4bb1-4e49-a729-c0a327c0700e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting alpaca-py\n  Downloading alpaca_py-0.43.2-py3-none-any.whl.metadata (13 kB)\nCollecting msgpack<2.0.0,>=1.0.3 (from alpaca-py)\n  Downloading msgpack-1.1.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\nRequirement already satisfied: pandas>=1.5.3 in /databricks/python3/lib/python3.12/site-packages (from alpaca-py) (2.2.3)\nRequirement already satisfied: pydantic<3.0.0,>=2.0.3 in /databricks/python3/lib/python3.12/site-packages (from alpaca-py) (2.10.6)\nRequirement already satisfied: requests<3.0.0,>=2.30.0 in /databricks/python3/lib/python3.12/site-packages (from alpaca-py) (2.32.3)\nCollecting sseclient-py<2.0.0,>=1.7.2 (from alpaca-py)\n  Downloading sseclient_py-1.9.0-py3-none-any.whl.metadata (1.9 kB)\nCollecting websockets>=10.4 (from alpaca-py)\n  Downloading websockets-16.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: numpy>=1.26.0 in /databricks/python3/lib/python3.12/site-packages (from pandas>=1.5.3->alpaca-py) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /databricks/python3/lib/python3.12/site-packages (from pandas>=1.5.3->alpaca-py) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.12/site-packages (from pandas>=1.5.3->alpaca-py) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /databricks/python3/lib/python3.12/site-packages (from pandas>=1.5.3->alpaca-py) (2024.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.3->alpaca-py) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.2 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.3->alpaca-py) (2.27.2)\nRequirement already satisfied: typing-extensions>=4.12.2 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.3->alpaca-py) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.12/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py) (2025.1.31)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.3->alpaca-py) (1.16.0)\nDownloading alpaca_py-0.43.2-py3-none-any.whl (122 kB)\nDownloading msgpack-1.1.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (427 kB)\nDownloading sseclient_py-1.9.0-py3-none-any.whl (8.4 kB)\nDownloading websockets-16.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (184 kB)\nInstalling collected packages: websockets, sseclient-py, msgpack, alpaca-py\nSuccessfully installed alpaca-py-0.43.2 msgpack-1.1.2 sseclient-py-1.9.0 websockets-16.0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install alpaca-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bac946d9-e34c-49e9-a98b-57769a90f8bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Símbolos a ingestar desde Alpaca: 40\n[INFO] Descargando TSLA ...\n[WARN] TSLA: sin datos\n[INFO] Descargando NVDA ...\n[WARN] NVDA: sin datos\n[INFO] Descargando AMD ...\n[WARN] AMD: sin datos\n[INFO] Descargando COIN ...\n[WARN] COIN: sin datos\n[INFO] Descargando PLTR ...\n[WARN] PLTR: sin datos\n[INFO] Descargando RIVN ...\n[WARN] RIVN: sin datos\n[INFO] Descargando SHOP ...\n[WARN] SHOP: sin datos\n[INFO] Descargando LCID ...\n[WARN] LCID: sin datos\n[INFO] Descargando ZM ...\n[WARN] ZM: sin datos\n[INFO] Descargando SPCE ...\n[WARN] SPCE: sin datos\n[INFO] Descargando KO ...\n[WARN] KO: sin datos\n[INFO] Descargando PG ...\n[WARN] PG: sin datos\n[INFO] Descargando JNJ ...\n[WARN] JNJ: sin datos\n[INFO] Descargando PEP ...\n[WARN] PEP: sin datos\n[INFO] Descargando WMT ...\n[WARN] WMT: sin datos\n[INFO] Descargando MCD ...\n[WARN] MCD: sin datos\n[INFO] Descargando VZ ...\n[WARN] VZ: sin datos\n[INFO] Descargando DUK ...\n[WARN] DUK: sin datos\n[INFO] Descargando UL ...\n[WARN] UL: sin datos\n[INFO] Descargando V ...\n[WARN] V: sin datos\n[INFO] Descargando SPY ...\n[WARN] SPY: sin datos\n[INFO] Descargando QQQ ...\n[WARN] QQQ: sin datos\n[INFO] Descargando EEM ...\n[WARN] EEM: sin datos\n[INFO] Descargando VGK ...\n[WARN] VGK: sin datos\n[INFO] Descargando AGG ...\n[WARN] AGG: sin datos\n[INFO] Descargando VNQ ...\n[WARN] VNQ: sin datos\n[INFO] Descargando ARKK ...\n[WARN] ARKK: sin datos\n[INFO] Descargando VUG ...\n[WARN] VUG: sin datos\n[INFO] Descargando SCHD ...\n[WARN] SCHD: sin datos\n[INFO] Descargando SOXX ...\n[WARN] SOXX: sin datos\n[INFO] Descargando GLD ...\n[WARN] GLD: sin datos\n[INFO] Descargando SLV ...\n[WARN] SLV: sin datos\n[INFO] Descargando PPLT ...\n[WARN] PPLT: sin datos\n[INFO] Descargando PALL ...\n[WARN] PALL: sin datos\n[INFO] Descargando USO ...\n[WARN] USO: sin datos\n[INFO] Descargando UNG ...\n[WARN] UNG: sin datos\n[INFO] Descargando CORN ...\n[WARN] CORN: sin datos\n[INFO] Descargando SOYB ...\n[WARN] SOYB: sin datos\n[INFO] Descargando WEAT ...\n[WARN] WEAT: sin datos\n[INFO] Descargando CANE ...\n[WARN] CANE: sin datos\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# ========== INGESTA OHLCV 1m HISTÓRICO DESDE ALPACA A BRONZE (DELTA) ==\n",
    "# ====================================================================\n",
    "\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from typing import Dict, List\n",
    "\n",
    "from alpaca.data.historical import StockHistoricalDataClient\n",
    "from alpaca.data.requests import StockBarsRequest\n",
    "from alpaca.data.timeframe import TimeFrame\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import year, month, dayofmonth, col\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# ================= CONFIGURACIÓN =================\n",
    "\n",
    "\n",
    "API_KEY_ID = dbutils.secrets.get(\n",
    "    scope=\"kv-scope\",\n",
    "    key=\"alpaca-key\"\n",
    ")\n",
    "\n",
    "SECRET_KEY = dbutils.secrets.get(\n",
    "    scope=\"kv-scope\",\n",
    "    key=\"alpaca-secret-key\"\n",
    ")\n",
    "\n",
    "TZ_DEFAULT = \"Europe/Madrid\"\n",
    "SOURCE_NAME = \"alpaca\"\n",
    "\n",
    "START_TIME = datetime(2025, 1, 1, 0, 0, tzinfo=timezone.utc)\n",
    "END_TIME   = datetime(2025, 12, 31, 23, 59, tzinfo=timezone.utc)\n",
    "\n",
    "bronze_base_path = (\n",
    "    \"abfss://datos@mastertfm002sta.dfs.core.windows.net/bronze/activos\"\n",
    ")\n",
    "\n",
    "# \uD83D\uDD35 Spark con soporte Delta\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# ================= ACTIVOS =================\n",
    "\n",
    "ASSET_GROUPS: Dict[str, List[Dict[str, str]]] = {\n",
    "    \"Acciones(S&P500)\": [\n",
    "        {\"symbol\": \"TSLA\"}, {\"symbol\": \"NVDA\"}, {\"symbol\": \"AMD\"},\n",
    "        {\"symbol\": \"COIN\"}, {\"symbol\": \"PLTR\"}, {\"symbol\": \"RIVN\"},\n",
    "        {\"symbol\": \"SHOP\"}, {\"symbol\": \"LCID\"}, {\"symbol\": \"ZM\"},\n",
    "        {\"symbol\": \"SPCE\"}, {\"symbol\": \"KO\"}, {\"symbol\": \"PG\"},\n",
    "        {\"symbol\": \"JNJ\"}, {\"symbol\": \"PEP\"}, {\"symbol\": \"WMT\"},\n",
    "        {\"symbol\": \"MCD\"}, {\"symbol\": \"VZ\"}, {\"symbol\": \"DUK\"},\n",
    "        {\"symbol\": \"UL\"}, {\"symbol\": \"V\"},\n",
    "    ],\n",
    "    \"Fondos(ETFs)\": [\n",
    "        {\"symbol\": \"SPY\"}, {\"symbol\": \"QQQ\"}, {\"symbol\": \"EEM\"},\n",
    "        {\"symbol\": \"VGK\"}, {\"symbol\": \"AGG\"}, {\"symbol\": \"VNQ\"},\n",
    "        {\"symbol\": \"ARKK\"}, {\"symbol\": \"VUG\"}, {\"symbol\": \"SCHD\"},\n",
    "        {\"symbol\": \"SOXX\"},\n",
    "    ],\n",
    "    \"Commodities(ETF)\": [\n",
    "        {\"symbol\": \"GLD\"}, {\"symbol\": \"SLV\"}, {\"symbol\": \"PPLT\"},\n",
    "        {\"symbol\": \"PALL\"}, {\"symbol\": \"USO\"}, {\"symbol\": \"UNG\"},\n",
    "        {\"symbol\": \"CORN\"}, {\"symbol\": \"SOYB\"}, {\"symbol\": \"WEAT\"},\n",
    "        {\"symbol\": \"CANE\"},\n",
    "    ],\n",
    "}\n",
    "\n",
    "ALL_SYMBOLS = [\n",
    "    item[\"symbol\"]\n",
    "    for group in ASSET_GROUPS.values()\n",
    "    for item in group\n",
    "]\n",
    "\n",
    "print(f\"[INFO] Símbolos a ingestar desde Alpaca: {len(ALL_SYMBOLS)}\")\n",
    "\n",
    "# ================= CLIENTE ALPACA =================\n",
    "\n",
    "client = StockHistoricalDataClient(\n",
    "    api_key=API_KEY_ID,\n",
    "    secret_key=SECRET_KEY\n",
    ")\n",
    "\n",
    "# ================= LIMPIEZA PREVIA (DELTA) =================\n",
    "\n",
    "# def delete_partitions_from_range(base_path, start_time, end_time):\n",
    "#     start_date = start_time.date()\n",
    "#     end_date = end_time.date()\n",
    "\n",
    "#     current = start_date\n",
    "#     while current <= end_date:\n",
    "#         path = (\n",
    "#             f\"{base_path}/year={current.year}\"\n",
    "#             f\"/month={current.month}\"\n",
    "#             f\"/day={current.day}\"\n",
    "#         )\n",
    "#         try:\n",
    "#             dbutils.fs.rm(path, recurse=True)\n",
    "#             print(f\"[CLEAN] Eliminada partición {path}\")\n",
    "#         except Exception:\n",
    "#             print(f\"[CLEAN] No existe {path}, se omite\")\n",
    "\n",
    "#         current += timedelta(days=1)\n",
    "\n",
    "# print(\n",
    "#     f\"[INFO] Limpiando Bronze Delta desde {START_TIME.date()} \"\n",
    "#     f\"hasta {END_TIME.date()}\"\n",
    "# )\n",
    "\n",
    "# delete_partitions_from_range(\n",
    "#     bronze_base_path,\n",
    "#     START_TIME,\n",
    "#     END_TIME\n",
    "# )\n",
    "\n",
    "# ================= INGESTA HISTÓRICA =================\n",
    "\n",
    "for symbol in ALL_SYMBOLS:\n",
    "    try:\n",
    "        print(f\"[INFO] Descargando {symbol} ...\")\n",
    "\n",
    "        request = StockBarsRequest(\n",
    "            symbol_or_symbols=symbol,\n",
    "            timeframe=TimeFrame.Minute,\n",
    "            start=START_TIME,\n",
    "            end=END_TIME,\n",
    "            feed=\"iex\"\n",
    "        )\n",
    "\n",
    "        bars = client.get_stock_bars(request)\n",
    "\n",
    "        if bars.df.empty:\n",
    "            print(f\"[WARN] {symbol}: sin datos\")\n",
    "            continue\n",
    "\n",
    "        pdf = bars.df.reset_index()\n",
    "\n",
    "        pdf.rename(columns={\n",
    "            \"timestamp\": \"Datetime\",\n",
    "            \"open\": \"Open\",\n",
    "            \"high\": \"High\",\n",
    "            \"low\": \"Low\",\n",
    "            \"close\": \"Close\",\n",
    "            \"volume\": \"Volume\",\n",
    "        }, inplace=True)\n",
    "\n",
    "        pdf[\"symbol\"] = symbol\n",
    "        pdf[\"timezone\"] = TZ_DEFAULT\n",
    "        pdf[\"source\"] = SOURCE_NAME\n",
    "\n",
    "        sdf = spark.createDataFrame(pdf)\n",
    "\n",
    "        sdf = (\n",
    "            sdf\n",
    "            .withColumnRenamed(\"Datetime\", \"timestamp\")\n",
    "            .withColumnRenamed(\"Open\", \"open\")\n",
    "            .withColumnRenamed(\"High\", \"high\")\n",
    "            .withColumnRenamed(\"Low\", \"low\")\n",
    "            .withColumnRenamed(\"Close\", \"close\")\n",
    "            .withColumnRenamed(\"Volume\", \"volume\")\n",
    "            .withColumn(\"volume\", col(\"volume\").cast(DoubleType()))\n",
    "            .withColumn(\"year\", year(\"timestamp\"))\n",
    "            .withColumn(\"month\", month(\"timestamp\"))\n",
    "            .withColumn(\"day\", dayofmonth(\"timestamp\"))\n",
    "            .select(\n",
    "                \"timestamp\",\n",
    "                \"symbol\",\n",
    "                \"open\",\n",
    "                \"high\",\n",
    "                \"low\",\n",
    "                \"close\",\n",
    "                \"volume\",\n",
    "                \"timezone\",\n",
    "                \"source\",\n",
    "                \"year\",\n",
    "                \"month\",\n",
    "                \"day\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # \uD83D\uDD35 ESCRITURA EN DELTA\n",
    "        (\n",
    "            sdf.write\n",
    "            .format(\"delta\")\n",
    "            .mode(\"append\")\n",
    "            .partitionBy(\"year\", \"month\", \"day\")\n",
    "            .save(bronze_base_path)\n",
    "        )\n",
    "\n",
    "        print(f\"[OK] {symbol} escrito en Bronze Delta\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {symbol}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Histórico-2025",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}