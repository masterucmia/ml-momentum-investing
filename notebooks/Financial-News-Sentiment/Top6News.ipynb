{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c752fbfb-edd1-4786-bbd4-8f2eac535a2d",
      "metadata": {
        "id": "c752fbfb-edd1-4786-bbd4-8f2eac535a2d"
      },
      "source": [
        "### Dependencias del entorno\n",
        "A continuaci√≥n se listan todas las librer√≠as instaladas asi como sus respectivas versiones\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba952f29-2c35-40bc-9d1d-4d853d200bbe",
      "metadata": {
        "id": "ba952f29-2c35-40bc-9d1d-4d853d200bbe",
        "outputId": "a365bc43-f568-42c5-e5e5-6afdba001dde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Package                   Version\n",
            "------------------------- -----------\n",
            "anyio                     4.12.1\n",
            "argon2-cffi               25.1.0\n",
            "argon2-cffi-bindings      25.1.0\n",
            "arrow                     1.4.0\n",
            "asttokens                 3.0.1\n",
            "async-lru                 2.1.0\n",
            "attrs                     25.4.0\n",
            "babel                     2.17.0\n",
            "beautifulsoup4            4.14.3\n",
            "bleach                    6.3.0\n",
            "certifi                   2026.1.4\n",
            "cffi                      2.0.0\n",
            "charset-normalizer        3.4.4\n",
            "colorama                  0.4.6\n",
            "comm                      0.2.3\n",
            "debugpy                   1.8.19\n",
            "decorator                 5.2.1\n",
            "defusedxml                0.7.1\n",
            "executing                 2.2.1\n",
            "fastjsonschema            2.21.2\n",
            "feedparser                6.0.12\n",
            "filelock                  3.20.3\n",
            "fqdn                      1.5.1\n",
            "fsspec                    2026.1.0\n",
            "h11                       0.16.0\n",
            "httpcore                  1.0.9\n",
            "httpx                     0.28.1\n",
            "huggingface-hub           0.36.0\n",
            "idna                      3.11\n",
            "ipykernel                 7.1.0\n",
            "ipython                   9.9.0\n",
            "ipython_pygments_lexers   1.1.1\n",
            "isoduration               20.11.0\n",
            "jedi                      0.19.2\n",
            "Jinja2                    3.1.6\n",
            "json5                     0.13.0\n",
            "jsonpointer               3.0.0\n",
            "jsonschema                4.26.0\n",
            "jsonschema-specifications 2025.9.1\n",
            "jupyter_client            8.8.0\n",
            "jupyter_core              5.9.1\n",
            "jupyter-events            0.12.0\n",
            "jupyter-lsp               2.3.0\n",
            "jupyter_server            2.17.0\n",
            "jupyter_server_terminals  0.5.4\n",
            "jupyterlab                4.5.2\n",
            "jupyterlab_pygments       0.3.0\n",
            "jupyterlab_server         2.28.0\n",
            "lark                      1.3.1\n",
            "MarkupSafe                3.0.3\n",
            "matplotlib-inline         0.2.1\n",
            "mistune                   3.2.0\n",
            "mpmath                    1.3.0\n",
            "nbclient                  0.10.4\n",
            "nbconvert                 7.16.6\n",
            "nbformat                  5.10.4\n",
            "nest-asyncio              1.6.0\n",
            "networkx                  3.6.1\n",
            "notebook                  7.5.2\n",
            "notebook_shim             0.2.4\n",
            "numpy                     2.4.1\n",
            "overrides                 7.7.0\n",
            "packaging                 25.0\n",
            "pandas                    2.3.3\n",
            "pandocfilters             1.5.1\n",
            "parso                     0.8.5\n",
            "pip                       25.3\n",
            "platformdirs              4.5.1\n",
            "prometheus_client         0.24.1\n",
            "prompt_toolkit            3.0.52\n",
            "psutil                    7.2.1\n",
            "pure_eval                 0.2.3\n",
            "pycparser                 2.23\n",
            "Pygments                  2.19.2\n",
            "python-dateutil           2.9.0.post0\n",
            "python-json-logger        4.0.0\n",
            "pytz                      2025.2\n",
            "pywinpty                  3.0.2\n",
            "PyYAML                    6.0.3\n",
            "pyzmq                     27.1.0\n",
            "referencing               0.37.0\n",
            "regex                     2026.1.15\n",
            "requests                  2.32.5\n",
            "rfc3339-validator         0.1.4\n",
            "rfc3986-validator         0.1.1\n",
            "rfc3987-syntax            1.1.0\n",
            "rpds-py                   0.30.0\n",
            "safetensors               0.7.0\n",
            "Send2Trash                2.1.0\n",
            "setuptools                80.9.0\n",
            "sgmllib3k                 1.0.0\n",
            "six                       1.17.0\n",
            "soupsieve                 2.8.2\n",
            "stack-data                0.6.3\n",
            "sympy                     1.14.0\n",
            "terminado                 0.18.1\n",
            "tinycss2                  1.4.0\n",
            "tokenizers                0.22.2\n",
            "torch                     2.9.1\n",
            "tornado                   6.5.4\n",
            "tqdm                      4.67.1\n",
            "traitlets                 5.14.3\n",
            "transformers              4.57.6\n",
            "typing_extensions         4.15.0\n",
            "tzdata                    2025.3\n",
            "uri-template              1.3.0\n",
            "urllib3                   2.6.3\n",
            "wcwidth                   0.2.14\n",
            "webcolors                 25.10.0\n",
            "webencodings              0.5.1\n",
            "websocket-client          1.9.0\n",
            "wheel                     0.45.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61feb7d7-c151-4521-b255-114449cc0526",
      "metadata": {
        "id": "61feb7d7-c151-4521-b255-114449cc0526"
      },
      "outputs": [],
      "source": [
        "#pip install requests feedparser\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2937c25-0235-4a9d-99ce-618ad8234406",
      "metadata": {
        "id": "b2937c25-0235-4a9d-99ce-618ad8234406"
      },
      "source": [
        "### Definici√≥n de lista blanca de dominios (GDELT / RSS)\n",
        "\n",
        "En esta celda se define `WHITELIST_DOMAINS`, un conjunto de dominios considerados **fuentes financieras y period√≠sticas fiables**\n",
        "\n",
        "Esta lista se utiliza posteriormente para:\n",
        "\n",
        "- Filtrar los resultados devueltos por GDELT y otras fuentes RSS.\n",
        "- Asegurar que solo se tienen en cuenta medios de comunicaci√≥n relevantes para el an√°lisis financiero del presente trabajo.\n",
        "- Reducir ruido y posibles sesgos derivados de fuentes de baja calidad.\n",
        "- Consulta a sitios no confiables.\n",
        "\n",
        "Esta decisi√≥n de dise√±o forma parte del control de calidad de los datos de entrada al modelo de sentimiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16e4b3b0-2725-4610-adab-69619aac9ef1",
      "metadata": {
        "id": "16e4b3b0-2725-4610-adab-69619aac9ef1"
      },
      "outputs": [],
      "source": [
        "#whitelists para GDELT\n",
        "WHITELIST_DOMAINS = {\n",
        "    \"reuters.com\",\n",
        "    \"bloomberg.com\",\n",
        "    \"wsj.com\",\n",
        "    \"ft.com\",\n",
        "    \"cnbc.com\",\n",
        "    \"finance.yahoo.com\",\n",
        "    \"marketwatch.com\",\n",
        "    \"investing.com\",\n",
        "    \"seekingalpha.com\",\n",
        "    \"fool.com\",\n",
        "    \"morningstar.com\",\n",
        "    \"thestreet.com\",\n",
        "    \"barrons.com\",\n",
        "    \"businessinsider.com\",\n",
        "    \"apnews.com\",\n",
        "    \"abcnews.go.com\",\n",
        "    \"nytimes.com\",\n",
        "    \"washingtonpost.com\",\n",
        "}\n",
        "\n",
        "def domain_allowed(domain: str, whitelist: set[str]) -> bool:\n",
        "    if not domain:\n",
        "        return False\n",
        "    d = domain.lower().strip()\n",
        "    return any(d == w or d.endswith(\".\" + w) for w in whitelist)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cc39f27-a7c5-4faa-9ff0-d31317d9c3c6",
      "metadata": {
        "id": "4cc39f27-a7c5-4faa-9ff0-d31317d9c3c6"
      },
      "source": [
        "# Declaraci√≥n de los helpers de preprocesado\n",
        "\n",
        "- Se define la zona horaria de referencia `MADRID_TZ` (Europa/Madrid), coherente con el contexto del presente trabajo.\n",
        "- Se implementan funciones auxiliares (_helpers_) para limpiar HTML, normalizar textos y manipular campos temporales,\n",
        "que se reutilizan en las funciones de obtenci√≥n de noticias.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4699e06e-77b2-4f36-b2dc-5225411325ea",
      "metadata": {
        "id": "4699e06e-77b2-4f36-b2dc-5225411325ea"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import feedparser\n",
        "from urllib.parse import quote\n",
        "from datetime import datetime, timezone\n",
        "from zoneinfo import ZoneInfo\n",
        "import re\n",
        "\n",
        "MADRID_TZ = ZoneInfo(\"Europe/Madrid\")\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Helpers\n",
        "# ---------------------------\n",
        "def _clean_html(text: str) -> str:\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    return re.sub(r\"<[^>]+>\", \"\", text).strip()\n",
        "\n",
        "\n",
        "def _today_local(tz=MADRID_TZ) -> datetime.date:\n",
        "    return datetime.now(tz).date()\n",
        "\n",
        "\n",
        "def _parse_gdelt_seendate(seendate: str):\n",
        "    \"\"\"\n",
        "    Soporta ambos formatos que puede devolver GDELT:\n",
        "    - 'YYYYMMDDHHMMSS' (antiguo)\n",
        "    - 'YYYYMMDDTHHMMSSZ' o 'YYYYMMDDT HHMMSS Z' (ej: 20260106T073000Z)\n",
        "    Devuelve datetime en UTC con tzinfo.\n",
        "    \"\"\"\n",
        "    if not seendate:\n",
        "        return None\n",
        "\n",
        "    s = seendate.strip()\n",
        "\n",
        "    # Formato: 20260106T073000Z\n",
        "    try:\n",
        "        if \"T\" in s and s.endswith(\"Z\"):\n",
        "            dt_utc = datetime.strptime(s, \"%Y%m%dT%H%M%SZ\").replace(tzinfo=timezone.utc)\n",
        "            return dt_utc\n",
        "    except ValueError:\n",
        "        pass\n",
        "\n",
        "    # Formato: 20260106073000\n",
        "    try:\n",
        "        dt_utc = datetime.strptime(s, \"%Y%m%d%H%M%S\").replace(tzinfo=timezone.utc)\n",
        "        return dt_utc\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "297069c9-9f49-4708-80ea-23139ed202ee",
      "metadata": {
        "id": "297069c9-9f49-4708-80ea-23139ed202ee"
      },
      "source": [
        "### Cliente RSS de GDELT: extracci√≥n de noticias recientes\n",
        "\n",
        "Esta celda implementa la l√≥gica para consumir el endpoint de documentos de **GDELT** y obtener noticias recientes relacionadas con una consulta (`query`):\n",
        "\n",
        "- Construye la URL a la API de GDELT (`/api/v2/doc/doc`).\n",
        "- Ajusta la ventana temporal de inter√©s (`hours`), t√≠pica de 24‚Äì48 h, para capturar noticias recientes.\n",
        "- Aplica funciones de limpieza y normalizaci√≥n de fechas a la salida.\n",
        "\n",
        "Esta funcionalidad proporciona una de las dos patas del enfoque h√≠brido de obtenci√≥n de noticias (GDELT + Google News RSS) utilizado en el TFM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13a15ee7-2eb7-4a4e-bf75-082588329dd4",
      "metadata": {
        "id": "13a15ee7-2eb7-4a4e-bf75-082588329dd4"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# GDELT\n",
        "\n",
        "\n",
        "from datetime import timedelta\n",
        "\n",
        "def fetch_gdelt_last_hours(query: str, n: int = 3, hours: int = 48, sourcelang: str = \"eng\", tz=MADRID_TZ):\n",
        "    url = \"https://api.gdeltproject.org/api/v2/doc/doc\"\n",
        "\n",
        "    # Sanitizar query para GDELT\n",
        "    query = query.replace(\"&\", \" and \")\n",
        "\n",
        "    now_utc = datetime.now(timezone.utc)\n",
        "    start_utc = now_utc - timedelta(hours=hours)\n",
        "\n",
        "    params = {\n",
        "        \"query\": query,\n",
        "        \"mode\": \"ArtList\",\n",
        "        \"format\": \"JSON\",\n",
        "        \"maxrecords\": 250,\n",
        "        \"sort\": \"datedesc\",\n",
        "        \"startdatetime\": start_utc.strftime(\"%Y%m%d%H%M%S\"),\n",
        "        \"enddatetime\": now_utc.strftime(\"%Y%m%d%H%M%S\"),\n",
        "    }\n",
        "    if sourcelang:\n",
        "        params[\"sourcelang\"] = sourcelang\n",
        "\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\", \"Accept\": \"application/json,*/*\"}\n",
        "\n",
        "    r = requests.get(url, params=params, headers=headers, timeout=20)\n",
        "    r.raise_for_status()\n",
        "\n",
        "    ct = (r.headers.get(\"content-type\") or \"\").lower()\n",
        "    if \"json\" not in ct:\n",
        "        raise RuntimeError(f\"GDELT no devolvi√≥ JSON (ct={ct}): {r.text[:200]!r}\")\n",
        "\n",
        "    data = r.json()\n",
        "\n",
        "    results = []\n",
        "    seen_titles = set()\n",
        "\n",
        "    for art in data.get(\"articles\", []) or []:\n",
        "        title = (art.get(\"title\") or \"\").strip()\n",
        "        link = (art.get(\"url\") or \"\").strip()\n",
        "        domain = (art.get(\"domain\") or \"\").lower().strip()\n",
        "        seendate = art.get(\"seendate\")\n",
        "\n",
        "        if not title or not link:\n",
        "            continue\n",
        "\n",
        "        # dedup por t√≠tulo\n",
        "        tkey = title.lower()\n",
        "        if tkey in seen_titles:\n",
        "            continue\n",
        "        seen_titles.add(tkey)\n",
        "\n",
        "        # Parse fecha\n",
        "        dt_utc = _parse_gdelt_seendate(seendate)\n",
        "        published_utc = dt_utc.isoformat() if dt_utc else None\n",
        "        published_local = dt_utc.astimezone(tz).isoformat() if dt_utc else None\n",
        "\n",
        "        results.append({\n",
        "            \"provider\": \"gdelt\",\n",
        "            \"title\": title,\n",
        "            \"link\": link,\n",
        "            \"source\": art.get(\"source\"),\n",
        "            \"domain\": domain,\n",
        "            \"seendate\": seendate,\n",
        "            \"published_utc\": published_utc,\n",
        "            \"published_local\": published_local,\n",
        "            \"summary\": art.get(\"summary\") or None,\n",
        "        })\n",
        "\n",
        "        if len(results) >= n:\n",
        "            break\n",
        "\n",
        "    return results\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12c258e1-950e-4fa9-8602-6612a5cc9083",
      "metadata": {
        "id": "12c258e1-950e-4fa9-8602-6612a5cc9083"
      },
      "source": [
        "### Cliente de Google News RSS (fallback)\n",
        "\n",
        "En esta celda se construye un **mecanismo de respaldo** basado en Google News RSS:\n",
        "\n",
        "- Se genera una URL RSS parametrizada con:\n",
        "  - `query`: t√©rmino o conjunto de t√©rminos de b√∫squeda.\n",
        "  - `lang` y `country`: idioma y pa√≠s de referencia.\n",
        "- Se aplican filtros temporales mediante `max_age_days` para limitar las noticias a una ventana reciente (por defecto, √∫ltimos 7 d√≠as).\n",
        "- Se parsea el feed con `feedparser` y se normalizan campos como t√≠tulo, resumen, enlace, fecha de publicaci√≥n y fuente.\n",
        "\n",
        "Este cliente se utiliza como complemento a GDELT para obtener una mayor cobertura  de noticias.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7504620a-ed23-425c-bcc0-a248d0315de8",
      "metadata": {
        "id": "7504620a-ed23-425c-bcc0-a248d0315de8"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Google News RSS (fallback)\n",
        "\n",
        "\n",
        "from email.utils import parsedate_to_datetime\n",
        "from datetime import timedelta\n",
        "\n",
        "def fetch_google_rss(\n",
        "    query: str,\n",
        "    n: int = 3,\n",
        "    lang: str = \"en\",\n",
        "    country: str = \"US\",\n",
        "    tz=MADRID_TZ,\n",
        "    max_age_days: int = 7,   # <-- filtro: √∫ltimos 7 d√≠as\n",
        "):\n",
        "    url = (\n",
        "        f\"https://news.google.com/rss/search?\"\n",
        "        f\"q={quote(query)}\"\n",
        "        f\"&hl={lang}\"\n",
        "        f\"&gl={country}\"\n",
        "        f\"&ceid={country}:{lang}\"\n",
        "    )\n",
        "    feed = feedparser.parse(url)\n",
        "\n",
        "    results = []\n",
        "    seen = set()\n",
        "\n",
        "    now_utc = datetime.now(timezone.utc)\n",
        "    cutoff_utc = now_utc - timedelta(days=max_age_days)\n",
        "\n",
        "    for e in feed.entries:\n",
        "        title = (getattr(e, \"title\", \"\") or \"\").strip()\n",
        "        link = (getattr(e, \"link\", \"\") or \"\").strip()\n",
        "        if not title or not link:\n",
        "            continue\n",
        "\n",
        "        key = title.lower()\n",
        "        if key in seen:\n",
        "            continue\n",
        "        seen.add(key)\n",
        "\n",
        "        summary = _clean_html(getattr(e, \"summary\", \"\") or \"\") or None\n",
        "        published_raw = getattr(e, \"published\", None)\n",
        "\n",
        "        # Parse fecha RSS ‚Üí UTC\n",
        "        dt_utc = None\n",
        "        if published_raw:\n",
        "            try:\n",
        "                dt = parsedate_to_datetime(published_raw)\n",
        "                if dt.tzinfo is None:\n",
        "                    dt = dt.replace(tzinfo=timezone.utc)\n",
        "                dt_utc = dt.astimezone(timezone.utc)\n",
        "            except Exception:\n",
        "                dt_utc = None\n",
        "\n",
        "        # Filtrar por recencia (si no hay fecha, lo descartamos para evitarregistros que son antiguos)\n",
        "        if dt_utc is None:\n",
        "            continue\n",
        "        if dt_utc < cutoff_utc:\n",
        "            continue\n",
        "\n",
        "        results.append({\n",
        "            \"provider\": \"rss\",\n",
        "            \"title\": title,\n",
        "            \"link\": link,\n",
        "            \"source\": getattr(getattr(e, \"source\", None), \"title\", None),\n",
        "            \"published\": published_raw,\n",
        "            \"published_utc\": dt_utc.isoformat(),\n",
        "            \"published_local\": dt_utc.astimezone(tz).isoformat(),\n",
        "            \"summary\": summary,\n",
        "        })\n",
        "\n",
        "        if len(results) >= n:\n",
        "            break\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82d027a8-c412-40cf-8d95-f4a3a0f00d75",
      "metadata": {
        "id": "82d027a8-c412-40cf-8d95-f4a3a0f00d75"
      },
      "source": [
        "### Construcci√≥n de queries sem√°nticas para √≠ndices burs√°tiles y activos\n",
        "\n",
        "La funci√≥n `build_query` transforma una entrada simple del usuario (por ejemplo, `SP500`, `NASDAQ100`, `IBEX35`) en una **query expandida** apta para:\n",
        "\n",
        "- GDELT (par√°metros de b√∫squeda avanzados).\n",
        "- Feeds RSS (Google News, agregadores financieros).\n",
        "\n",
        "Caracter√≠sticas clave:\n",
        "\n",
        "- Mapea alias conocidos (SP500, S&P500, NASDAQ100, IBEX35, etc.) a expresiones con sin√≥nimos, tickers y ETFs representativos.\n",
        "- Permite capturar distintas formas en las que la prensa financiera se refiere al mismo √≠ndice.\n",
        "- Devuelve una cadena lista para ser utilizada en las funciones de consulta posteriores.\n",
        "\n",
        "Esta capa de aliasing mejora la **recuperaci√≥n de noticias relevantes** para el activo/√≠ndice de inter√©s en el marco del TFM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e34cd76-ed2b-4d82-ac4d-eaf96ea9878c",
      "metadata": {
        "id": "3e34cd76-ed2b-4d82-ac4d-eaf96ea9878c"
      },
      "outputs": [],
      "source": [
        "def load_aliases_from_txt(path: str) -> dict[str, str]:\n",
        "    aliases = {}\n",
        "    with open(path, encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            if \"=\" not in line:\n",
        "                continue\n",
        "            key, value = line.split(\"=\", 1)\n",
        "            aliases[key.strip().upper()] = value.strip()\n",
        "    return aliases\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e6f1fe0-cc0b-4c93-8ce3-94fe9dc8589d",
      "metadata": {
        "id": "0e6f1fe0-cc0b-4c93-8ce3-94fe9dc8589d"
      },
      "outputs": [],
      "source": [
        "ALIASES = load_aliases_from_txt(\"C:\\\\Users\\\\migue\\\\Documents\\\\TFM\\\\aliases.txt\")\n",
        "\n",
        "def build_query(user_input: str) -> str:\n",
        "    s = user_input.strip()\n",
        "    key = s.upper().replace(\" \", \"\")\n",
        "    if key in ALIASES:\n",
        "        return ALIASES[key]\n",
        "\n",
        "    if s.isupper() and len(s) <= 6:\n",
        "        return f'(\"{s}\" AND (stock OR shares OR earnings OR market))'\n",
        "\n",
        "    if \" \" in s:\n",
        "        return f'(\"{s}\" AND (stock OR shares OR earnings OR market))'\n",
        "\n",
        "    return s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "027c52ec-e6e3-498f-83b2-82003f20c0e3",
      "metadata": {
        "id": "027c52ec-e6e3-498f-83b2-82003f20c0e3"
      },
      "outputs": [],
      "source": [
        "def build_query_old(user_input: str) -> str:\n",
        "    \"\"\"\n",
        "    Convierte una entrada simple del usuario en una query usable para GDELT/RSS.\n",
        "    \"\"\"\n",
        "    s = user_input.strip()\n",
        "\n",
        "    aliases = {\n",
        "        \"SP500\": '\"S and P 500\" OR \"S&P500\" OR SPX OR \"^GSPC\" OR \"SPY ETF\" OR \"SPDR S&P 500 ETF\" OR \"SPDR S&P 500 ETF Trust\"',\n",
        "        \"S&P500\": '\"S and P 500\" OR \"S&P500\" OR SPX OR \"^GSPC\" OR \"SPY ETF\" OR \"SPDR S&P 500 ETF\" OR \"SPDR S&P 500 ETF Trust\"',\n",
        "        \"NASDAQ100\": '(\"Nasdaq 100\" OR NDX OR QQQ)',\n",
        "        \"IBEX35\": '(\"IBEX 35\" OR IBEX)',\n",
        "    }\n",
        "\n",
        "    key = s.upper().replace(\" \", \"\")\n",
        "    if key in aliases:\n",
        "        return aliases[key]\n",
        "\n",
        "    # Si parece ticker (AAPL, TSLA, SAN, etc.)\n",
        "    if s.isupper() and len(s) <= 6:\n",
        "        return f'(\"{s}\" AND (stock OR shares OR earnings OR market))'\n",
        "\n",
        "    # Si es texto libre (nombre empresa)\n",
        "    if \" \" in s:\n",
        "        return f'(\"{s}\" AND (stock OR shares OR earnings OR market))'\n",
        "\n",
        "    return s\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82c1d4a2-b07d-4afa-a46e-6ae1078984bf",
      "metadata": {
        "id": "82c1d4a2-b07d-4afa-a46e-6ae1078984bf"
      },
      "source": [
        "### Construcci√≥n de URLs para feeds RSS (query final)\n",
        "\n",
        "La funci√≥n `make_rss_query_from_base` recibe una URL base de RSS (por ejemplo, de Google News) y una `query` ya procesada:\n",
        "\n",
        "- Ensambla la URL completa con par√°metros codificados correctamente.\n",
        "- Garantiza que los operadores l√≥gicos y caracteres especiales se transmiten en un formato aceptado por el proveedor RSS.\n",
        "\n",
        "El resultado es una URL lista para ser consumida por `feedparser`, integrando as√≠ la capa de construcci√≥n de consultas con la capa de obtenci√≥n de datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41d6cb24-3dce-49c5-97e5-d94c64a40ed2",
      "metadata": {
        "id": "41d6cb24-3dce-49c5-97e5-d94c64a40ed2"
      },
      "outputs": [],
      "source": [
        "def make_rss_query_from_base(base: str) -> str:\n",
        "    \"\"\"\n",
        "    Convierte una base tipo GDELT (ORs) en una query simple para Google News RSS.\n",
        "    \"\"\"\n",
        "    q = base\n",
        "    q = re.sub(r\"\\bsourcelang:\\w+\\b\", \"\", q, flags=re.IGNORECASE)\n",
        "    q = q.replace(\"(\", \" \").replace(\")\", \" \")\n",
        "    q = re.sub(r\"\\s+\", \" \", q).strip()\n",
        "    return q\n",
        "\n",
        "\n",
        "def fetch_news_hybrid_3_and_3(\n",
        "    user_input: str,\n",
        "    gdelt_n: int = 3,\n",
        "    rss_n: int = 3,\n",
        "    gdelt_lang: str = \"eng\",\n",
        "    rss_lang: str = \"en\",\n",
        "    rss_country: str = \"US\",\n",
        "    hours: int = 48,\n",
        "    rss_max_age_days: int = 2,   # üëà AQU√ç controlas ayer + hoy\n",
        "):\n",
        "    \"\"\"\n",
        "    Devuelve (si existen):\n",
        "    - 3 art√≠culos de GDELT (√∫ltimas `hours` horas)\n",
        "    - 3 art√≠culos de RSS (√∫ltimos `rss_max_age_days` d√≠as)\n",
        "\n",
        "    No hace fallback cruzado: cada fuente es independiente.\n",
        "    \"\"\"\n",
        "\n",
        "    # --------------------------------------------------\n",
        "    # Construir queries\n",
        "    # --------------------------------------------------\n",
        "    base = build_query(user_input)  # OR plano\n",
        "\n",
        "    query_gdelt = f'sourcelang:english ({base}) AND market'\n",
        "    query_rss = make_rss_query_from_base(base)\n",
        "\n",
        "    # --------------------------------------------------\n",
        "    # 1) GDELT\n",
        "    # --------------------------------------------------\n",
        "    gdelt_items = []\n",
        "    try:\n",
        "        gdelt_items = fetch_gdelt_last_hours(\n",
        "            query_gdelt,\n",
        "            n=gdelt_n,\n",
        "            hours=hours,\n",
        "            sourcelang=gdelt_lang\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(\"GDELT error:\", e)\n",
        "        gdelt_items = []\n",
        "\n",
        "    for it in gdelt_items:\n",
        "        it.setdefault(\"provider\", \"gdelt\")\n",
        "\n",
        "    # --------------------------------------------------\n",
        "    # 2) RSS (con filtro de d√≠as)\n",
        "    # --------------------------------------------------\n",
        "    rss_items = []\n",
        "    try:\n",
        "        rss_items = fetch_google_rss(\n",
        "            query_rss,\n",
        "            n=rss_n,\n",
        "            lang=rss_lang,\n",
        "            country=rss_country,\n",
        "            max_age_days=rss_max_age_days\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(\"RSS error:\", e)\n",
        "        rss_items = []\n",
        "\n",
        "    for it in rss_items:\n",
        "        it.setdefault(\"provider\", \"rss\")\n",
        "\n",
        "    # --------------------------------------------------\n",
        "    # 3) Merge + dedup global\n",
        "    # --------------------------------------------------\n",
        "    merged = []\n",
        "    seen_links = set()\n",
        "    seen_titles = set()\n",
        "\n",
        "    def add_item(item):\n",
        "        link = (item.get(\"link\") or \"\").strip()\n",
        "        title = (item.get(\"title\") or \"\").strip().lower()\n",
        "\n",
        "        if link and link in seen_links:\n",
        "            return\n",
        "        if title and title in seen_titles:\n",
        "            return\n",
        "\n",
        "        if link:\n",
        "            seen_links.add(link)\n",
        "        if title:\n",
        "            seen_titles.add(title)\n",
        "\n",
        "        merged.append(item)\n",
        "\n",
        "    for it in gdelt_items[:gdelt_n]:\n",
        "        add_item(it)\n",
        "\n",
        "    for it in rss_items[:rss_n]:\n",
        "        add_item(it)\n",
        "\n",
        "    return {\n",
        "        \"source\": \"gdelt+rss\",\n",
        "        \"queries\": {\n",
        "            \"gdelt\": query_gdelt,\n",
        "            \"rss\": query_rss,\n",
        "        },\n",
        "        \"counts\": {\n",
        "            \"gdelt_requested\": gdelt_n,\n",
        "            \"rss_requested\": rss_n,\n",
        "            \"gdelt_returned\": len(gdelt_items[:gdelt_n]),\n",
        "            \"rss_returned\": len(rss_items[:rss_n]),\n",
        "            \"total_returned\": len(merged),\n",
        "        },\n",
        "        \"items\": merged,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a18f6156-d634-4022-acd4-92f65e7997c8",
      "metadata": {
        "id": "a18f6156-d634-4022-acd4-92f65e7997c8"
      },
      "source": [
        "### Ejecuci√≥n de la metodolog√≠a implementada h√≠brida de noticias (GDELT + RSS) para losa ctivos definidos.\n",
        "\n",
        "En esta celda se invoca `fetch_news_hybrid_3_and_3` con el t√©rmino `\"SP500\"` y una restricci√≥n temporal (`rss_max_age_days=2`) que acota las noticias a ayer + hoy.\n",
        "\n",
        "Objetivos de la celda:\n",
        "\n",
        "- Comprobar que el pipeline de obtenci√≥n de noticias funciona de extremo a extremo.\n",
        "- Inspeccionar el n√∫mero de noticias devueltas por cada proveedor (`counts`).\n",
        "- Revisar t√≠tulos, fechas y fuentes para validar la calidad de los datos que se utilizar√°n m√°s adelante en el an√°lisis de sentimiento.\n",
        "\n",
        "Esta celda es √∫til a modo de **prueba de integraci√≥n** dentro del TFM.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "881de31e-2320-4082-a91d-70b8d61f340e",
      "metadata": {
        "id": "881de31e-2320-4082-a91d-70b8d61f340e"
      },
      "source": [
        "### Aqui yo realizo las pruebas para probar que el diccionario funciona con los activos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd7ead7b-fb7d-4879-ba5c-8392f69c8f76",
      "metadata": {
        "id": "cd7ead7b-fb7d-4879-ba5c-8392f69c8f76",
        "outputId": "e574e7eb-4851-4db7-d3e5-9d8ce74ef0c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'gdelt_requested': 3, 'rss_requested': 3, 'gdelt_returned': 1, 'rss_returned': 3, 'total_returned': 4}\n",
            "\n",
            "1. [GDELT] Dollar sold ; JPY gains amid rate check speculation - Newsquawk US Market Wrap\n",
            "   Date: 2026-01-24T01:45:00+01:00\n",
            "   Source: zerohedge.com\n",
            "\n",
            "2. [RSS] Spain stocks lower at close of trade; IBEX 35 down 0.67% - Investing.com\n",
            "   Date: 2026-01-23T18:30:11+01:00\n",
            "   Source: Investing.com\n",
            "\n",
            "3. [RSS] Spain shares lower at close of trade; IBEX 35 down 0.67% - Investing.com India\n",
            "   Date: 2026-01-23T18:27:43+01:00\n",
            "   Source: Investing.com India\n",
            "\n",
            "4. [RSS] Spain shares lower at close of trade; IBEX 35 down 0.67% - Investing.com UK\n",
            "   Date: 2026-01-23T18:05:00+01:00\n",
            "   Source: Investing.com UK\n"
          ]
        }
      ],
      "source": [
        "out = fetch_news_hybrid_3_and_3(\n",
        "    \"IBEX35\",\n",
        "    rss_max_age_days=2\n",
        ")\n",
        "\n",
        "print(out[\"counts\"])\n",
        "for i, item in enumerate(out[\"items\"], 1):\n",
        "    print(f\"\\n{i}. [{item['provider'].upper()}] {item['title']}\")\n",
        "    print(\"   Date:\", item.get(\"published_local\") or item.get(\"published_utc\") or item.get(\"published\"))\n",
        "    print(\"   Source:\", item.get(\"source\") or item.get(\"domain\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fee7fec6-0685-4f27-9135-9198c2ade471",
      "metadata": {
        "id": "fee7fec6-0685-4f27-9135-9198c2ade471"
      },
      "source": [
        "### Inspecci√≥n detallada de los √≠tems devueltos por el pipeline h√≠brido\n",
        "\n",
        "Partiendo de la salida `out[\"items\"]` generada en la celda anterior, aqu√≠ se recorre la lista de noticias para:\n",
        "\n",
        "- Imprimir t√≠tulo, enlace, fuente y fecha normalizada de cada √≠tem.\n",
        "- Verificar que la informaci√≥n relevante para el an√°lisis (t√≠tulo, resumen, metadatos temporales) est√© correctamente formateada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c66c66fb-4e38-4a03-84ca-df92f0d38763",
      "metadata": {
        "id": "c66c66fb-4e38-4a03-84ca-df92f0d38763",
        "outputId": "30f9f6e5-9619-408c-aeef-e2372235f61a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "1. [GDELT] Dollar sold ; JPY gains amid rate check speculation - Newsquawk US Market Wrap\n",
            "   Link: https://www.zerohedge.com/markets/dollar-sold-jpy-gains-amid-rate-check-speculation-newsquawk-us-market-wrap\n",
            "   Source: zerohedge.com\n",
            "   Date: 2026-01-24T01:45:00+01:00\n",
            "\n",
            "2. [RSS] Spain stocks lower at close of trade; IBEX 35 down 0.67% - Investing.com\n",
            "   Link: https://news.google.com/rss/articles/CBMirwFBVV95cUxNSzJDakNhSWlHR2dpdkVsZmozRzFCVk5YN19XVkVBeVFfYm45Uk9hSzI0UDNURE9SUlJoWlc3WnFKQ0FJc0JhTDVSbVBCdkhyR3FoeVlYS1hSRXlMd2ZNN0VBbDJaZ2JqUGtXVzFzYkNBSkMwTkN0RFNBN24tVXRKVEg1aENlNFpGekFwaWxLWE1kLTFIRUJBb2NrXzktek8xdnRLVjhReUc1TC16ZE5z?oc=5\n",
            "   Source: Investing.com\n",
            "   Date: 2026-01-23T18:30:11+01:00\n",
            "   Summary: Spain stocks lower at close of trade; IBEX 35 down 0.67%&nbsp;&nbsp;Investing.com\n",
            "\n",
            "3. [RSS] Spain shares lower at close of trade; IBEX 35 down 0.67% - Investing.com India\n",
            "   Link: https://news.google.com/rss/articles/CBMirgFBVV95cUxQWWRTVGdOeGxac21LekZsbm1tYXBlU3pwSDFZamVfNHEzU2NzTFVsbVdaMUVqc0E3RlpSV3ROUGJFdmkzdEM3TTBjRXFnWllZbTRsemFiZGJUdEhFbHFPSURLWFVicEFoOWh2alZWcDE1R2djM2UxRVc1Wm9mcm9hY2FTeTlucUFsSHFHR2FsS2t2SkJ5UXZKRl9TU0lKQU1NemlJR00wNWJDVVpnY0E?oc=5\n",
            "   Source: Investing.com India\n",
            "   Date: 2026-01-23T18:27:43+01:00\n",
            "   Summary: Spain shares lower at close of trade; IBEX 35 down 0.67%&nbsp;&nbsp;Investing.com India\n",
            "\n",
            "4. [RSS] Spain shares lower at close of trade; IBEX 35 down 0.67% - Investing.com UK\n",
            "   Link: https://news.google.com/rss/articles/CBMirgFBVV95cUxON1FlYTNfbFlURzh1cm9weHNCQnNCdXBNX2s2dTFKS2RvV2xLTGFDSnl1SnJvRzBhUFVwWEVBX2VSbi14ZWdvYUZGSERpbWQ3X3ZFaGpyWmkwVUNwLVlmVWVSUnA1OFNsMVlpQy01Z0wteVkwTVFMVDI3Yk1xZVFGTWIyTTVzZ0xMaTExc2VtUXJ5aHZlZ0ZyX245RVJPU0Nqc1cwV0RuM1JYMEtJY0E?oc=5\n",
            "   Source: Investing.com UK\n",
            "   Date: 2026-01-23T18:05:00+01:00\n",
            "   Summary: Spain shares lower at close of trade; IBEX 35 down 0.67%&nbsp;&nbsp;Investing.com UK\n"
          ]
        }
      ],
      "source": [
        "for i, item in enumerate(out[\"items\"], 1):\n",
        "    print(f\"\\n{i}. [{item['provider'].upper()}] {item['title']}\")\n",
        "    print(\"   Link:\", item.get(\"link\"))\n",
        "    print(\"   Source:\", item.get(\"source\") or item.get(\"domain\"))\n",
        "    date = item.get(\"published_local\") or item.get(\"published_utc\") or item.get(\"published\")\n",
        "    print(\"   Date:\", date)\n",
        "    if item.get(\"summary\"):\n",
        "        print(\"   Summary:\", item[\"summary\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a674340b-a191-4a38-aa37-d82dcbc7ff5f",
      "metadata": {
        "id": "a674340b-a191-4a38-aa37-d82dcbc7ff5f"
      },
      "outputs": [],
      "source": [
        "#!pip install -q transformers torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8174959-0565-404f-9f7f-861f4ca3f600",
      "metadata": {
        "id": "f8174959-0565-404f-9f7f-861f4ca3f600"
      },
      "source": [
        "### Carga del modelo de sentimiento financiero (FinBERT)\n",
        "\n",
        "Aqu√≠ se inicializa un `pipeline` de `transformers` para la tarea de `sentiment-analysis` utilizando el modelo:\n",
        "\n",
        "- `ProsusAI/finbert`, una variante de BERT especializada en **texto financiero**.\n",
        "\n",
        "Este componente es clave en el TFM, ya que convierte textos de noticias en etiquetas de sentimiento (`positive`, `neutral`, `negative`) con una probabilidad asociada, lo que m√°s adelante se traducir√° en una se√±al num√©rica.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8413fbf5-408d-445a-bd53-8151335db3bf",
      "metadata": {
        "id": "8413fbf5-408d-445a-bd53-8151335db3bf",
        "outputId": "965214bb-5814-4697-9c8d-17ca4f5896a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\migue\\anaconda3\\envs\\nlp-news\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "sentiment_model = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"ProsusAI/finbert\",\n",
        "    tokenizer=\"ProsusAI/finbert\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b447c89-9039-4d0e-aa96-9159aa9d6f82",
      "metadata": {
        "id": "1b447c89-9039-4d0e-aa96-9159aa9d6f82"
      },
      "source": [
        "### Comprobaci√≥n de versiones de `torch` y `transformers`\n",
        "\n",
        "Esta celda imprime las versiones instaladas de:\n",
        "\n",
        "- `torch`\n",
        "- `transformers`\n",
        "\n",
        "Para este caso se tiene que tener una versi√≥n de torch arriba de 2.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0957d35-0e99-465f-a17a-0d1e336ac68c",
      "metadata": {
        "id": "e0957d35-0e99-465f-a17a-0d1e336ac68c",
        "outputId": "192f523b-dae8-47b5-e26c-3da2b0ef2216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.9.1+cpu\n",
            "4.57.6\n"
          ]
        }
      ],
      "source": [
        "import torch, transformers\n",
        "print(torch.__version__)\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96ef78d8-526a-4376-9fb1-d02834b4ed33",
      "metadata": {
        "id": "96ef78d8-526a-4376-9fb1-d02834b4ed33"
      },
      "source": [
        "### Construcci√≥n del texto de entrada para el modelo de sentimiento\n",
        "\n",
        "La funci√≥n `build_text_for_sentiment` define c√≥mo se combina la informaci√≥n de cada noticia para alimentar el modelo de an√°lisis de sentimiento:\n",
        "\n",
        "- Prioriza el uso conjunto de `title` + `summary` cuando ambos est√°n disponibles.\n",
        "- Si solo hay t√≠tulo, utiliza √∫nicamente ese campo.\n",
        "\n",
        "Esta decisi√≥n controla el **contexto textual** con el que FinBERT eval√∫a cada noticia y, por tanto, influye en la clasificaci√≥n de sentimiento que se obtiene.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65b2e080-8c8d-438d-b557-192423fd5f93",
      "metadata": {
        "id": "65b2e080-8c8d-438d-b557-192423fd5f93"
      },
      "outputs": [],
      "source": [
        "def build_text_for_sentiment(item: dict) -> str:\n",
        "    title = (item.get(\"title\") or \"\").strip()\n",
        "    summary = (item.get(\"summary\") or \"\").strip()\n",
        "    if summary:\n",
        "        return f\"{title}. {summary}\"\n",
        "    return title"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9334bcd5-d6da-47d5-8054-fb46213b92d9",
      "metadata": {
        "id": "9334bcd5-d6da-47d5-8054-fb46213b92d9"
      },
      "source": [
        "### Ejecuci√≥n del pipeline de noticias para el activo elegido (entrada al an√°lisis de sentimiento)\n",
        "\n",
        "En esta celda se vuelve a invocar `fetch_news_hybrid_3_and_3`, en este caso de forma m√°s directa, y se almacena el resultado en:\n",
        "\n",
        "- `out`: diccionario con metadatos y la lista de noticias.\n",
        "- `items`: lista de √≠tems, cada uno con t√≠tulo, enlace, fechas y, eventualmente, resumen.\n",
        "\n",
        "Estos `items` son la **materia prima** sobre la que se aplicar√° el modelo de sentimiento en las celdas siguientes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7ef86a0-9dae-4cf6-bf32-d72d8bc30448",
      "metadata": {
        "id": "f7ef86a0-9dae-4cf6-bf32-d72d8bc30448"
      },
      "source": [
        "### En la siguiente celda, la entrada es la clave para el activo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "816711c9-e0bf-4736-a838-cab1d0f1b701",
      "metadata": {
        "id": "816711c9-e0bf-4736-a838-cab1d0f1b701"
      },
      "outputs": [],
      "source": [
        "out = fetch_news_hybrid_3_and_3(\"SP500\")\n",
        "items = out[\"items\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6289f703-5862-46ab-852f-eb1ce78395e3",
      "metadata": {
        "id": "6289f703-5862-46ab-852f-eb1ce78395e3"
      },
      "outputs": [],
      "source": [
        "out = fetch_news_hybrid_3_and_3(\"IBEX35\")\n",
        "items = out[\"items\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "823860d9-6db9-4a9f-b47f-3e19b0c21174",
      "metadata": {
        "id": "823860d9-6db9-4a9f-b47f-3e19b0c21174"
      },
      "source": [
        "### Aplicaci√≥n del modelo de sentimiento a cada noticia\n",
        "\n",
        "Esta celda recorre la lista `items` y, para cada noticia:\n",
        "\n",
        "1. Construye el texto de entrada mediante `build_text_for_sentiment`.\n",
        "2. Llama al `sentiment_model` (FinBERT financiero) para obtener:\n",
        "   - `label`: `positive`, `neutral` o `negative`.\n",
        "   - `score`: confianza asociada a esa predicci√≥n.\n",
        "3. Almacena en el propio diccionario de la noticia:\n",
        "   - `sentiment` (etiqueta categ√≥rica).\n",
        "   - `sentiment_score` (probabilidad).\n",
        "\n",
        "De este modo, cada noticia pasa a estar enriquecida con informaci√≥n de sentimiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6a4e4c1-8ed4-44c1-a367-525a5dc4fbe6",
      "metadata": {
        "id": "a6a4e4c1-8ed4-44c1-a367-525a5dc4fbe6"
      },
      "outputs": [],
      "source": [
        "for item in items:\n",
        "    text = build_text_for_sentiment(item)\n",
        "    if not text:\n",
        "        item[\"sentiment\"] = None\n",
        "        item[\"sentiment_score\"] = None\n",
        "        continue\n",
        "\n",
        "    pred = sentiment_model(text)[0]   # {'label': 'positive'/'neutral'/'negative', 'score': ...}\n",
        "\n",
        "    item[\"sentiment\"] = pred[\"label\"]\n",
        "    item[\"sentiment_score\"] = float(pred[\"score\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce3f4a0b-8183-48b6-ae24-23618582c6c2",
      "metadata": {
        "id": "ce3f4a0b-8183-48b6-ae24-23618582c6c2"
      },
      "source": [
        "### Transformaci√≥n del sentimiento categ√≥rico a valor num√©rico\n",
        "\n",
        "En esta celda se define el mapeo:\n",
        "\n",
        "- `positive` ‚Üí `+1`\n",
        "- `neutral`  ‚Üí `0`\n",
        "- `negative` ‚Üí `‚àí1`\n",
        "\n",
        "y se calcula, para cada noticia, el campo:\n",
        "\n",
        "- `sentiment_value = LABEL_TO_NUM[label] * score`\n",
        "\n",
        "Es decir, el signo viene dado por la polaridad y la magnitud por la confianza del modelo. Este valor escalar es especialmente √∫til para la construcci√≥n de indicadores cuantitativos de sentimiento en el marco del TFM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d111f6f-2c8c-414b-8855-4f25447bda34",
      "metadata": {
        "id": "4d111f6f-2c8c-414b-8855-4f25447bda34",
        "outputId": "84e49662-5310-44e1-e59f-d1cf54435b04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "1. [GDELT] Dollar sold ; JPY gains amid rate check speculation - Newsquawk US Market Wrap\n",
            "   Date: 2026-01-24T01:45:00+01:00\n",
            "   Sentiment: positive (0.83)\n",
            "   Link: https://www.zerohedge.com/markets/dollar-sold-jpy-gains-amid-rate-check-speculation-newsquawk-us-market-wrap\n",
            "\n",
            "2. [RSS] Spain stocks lower at close of trade; IBEX 35 down 0.67% - Investing.com\n",
            "   Date: 2026-01-23T18:30:11+01:00\n",
            "   Sentiment: negative (0.97)\n",
            "   Link: https://news.google.com/rss/articles/CBMirwFBVV95cUxNSzJDakNhSWlHR2dpdkVsZmozRzFCVk5YN19XVkVBeVFfYm45Uk9hSzI0UDNURE9SUlJoWlc3WnFKQ0FJc0JhTDVSbVBCdkhyR3FoeVlYS1hSRXlMd2ZNN0VBbDJaZ2JqUGtXVzFzYkNBSkMwTkN0RFNBN24tVXRKVEg1aENlNFpGekFwaWxLWE1kLTFIRUJBb2NrXzktek8xdnRLVjhReUc1TC16ZE5z?oc=5\n",
            "\n",
            "3. [RSS] Spain shares lower at close of trade; IBEX 35 down 0.67% - Investing.com India\n",
            "   Date: 2026-01-23T18:27:43+01:00\n",
            "   Sentiment: negative (0.97)\n",
            "   Link: https://news.google.com/rss/articles/CBMirgFBVV95cUxQWWRTVGdOeGxac21LekZsbm1tYXBlU3pwSDFZamVfNHEzU2NzTFVsbVdaMUVqc0E3RlpSV3ROUGJFdmkzdEM3TTBjRXFnWllZbTRsemFiZGJUdEhFbHFPSURLWFVicEFoOWh2alZWcDE1R2djM2UxRVc1Wm9mcm9hY2FTeTlucUFsSHFHR2FsS2t2SkJ5UXZKRl9TU0lKQU1NemlJR00wNWJDVVpnY0E?oc=5\n",
            "\n",
            "4. [RSS] Spain shares lower at close of trade; IBEX 35 down 0.67% - Investing.com UK\n",
            "   Date: 2026-01-23T18:05:00+01:00\n",
            "   Sentiment: negative (0.97)\n",
            "   Link: https://news.google.com/rss/articles/CBMirgFBVV95cUxON1FlYTNfbFlURzh1cm9weHNCQnNCdXBNX2s2dTFKS2RvV2xLTGFDSnl1SnJvRzBhUFVwWEVBX2VSbi14ZWdvYUZGSERpbWQ3X3ZFaGpyWmkwVUNwLVlmVWVSUnA1OFNsMVlpQy01Z0wteVkwTVFMVDI3Yk1xZVFGTWIyTTVzZ0xMaTExc2VtUXJ5aHZlZ0ZyX245RVJPU0Nqc1cwV0RuM1JYMEtJY0E?oc=5\n"
          ]
        }
      ],
      "source": [
        "for i, item in enumerate(items, 1):\n",
        "    date = item.get(\"published_local\") or item.get(\"published_utc\") or item.get(\"published\")\n",
        "    print(f\"\\n{i}. [{item['provider'].upper()}] {item['title']}\")\n",
        "    print(\"   Date:\", date)\n",
        "    print(\"   Sentiment:\", item.get(\"sentiment\"), f\"({item.get('sentiment_score'):.2f})\" if item.get(\"sentiment_score\") is not None else \"\")\n",
        "    print(\"   Link:\", item.get(\"link\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74f5fbc4-132d-4fad-961f-2f8d3b264aff",
      "metadata": {
        "id": "74f5fbc4-132d-4fad-961f-2f8d3b264aff"
      },
      "source": [
        "### Inspecci√≥n de resultados de sentimiento a nivel de noticia\n",
        "\n",
        "A partir de los valores calculados en la celda anterior, aqu√≠ se imprime, para cada noticia:\n",
        "\n",
        "- T√≠tulo.\n",
        "- Etiqueta de sentimiento (`sentiment`) y su probabilidad (`sentiment_score`).\n",
        "- Valor num√©rico agregado (`sentiment_value`).\n",
        "\n",
        "Esta inspecci√≥n permite comprobar la coherencia de las predicciones del modelo de sentimiento con el contenido intuitivo de las noticias, a√±adiendo una capa de validaci√≥n cualitativa al TFM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "300484da-e80c-4b6d-886f-47403410045c",
      "metadata": {
        "id": "300484da-e80c-4b6d-886f-47403410045c",
        "outputId": "cc942df8-243f-4891-f6d6-85b2c03680b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Dollar sold ; JPY gains amid rate check speculation - Newsquawk US Market Wrap\n",
            "   Sentiment: positive (0.83)\n",
            "   Sentiment value: 0.8326207399368286\n",
            "2. Spain stocks lower at close of trade; IBEX 35 down 0.67% - Investing.com\n",
            "   Sentiment: negative (0.97)\n",
            "   Sentiment value: -0.9684360027313232\n",
            "3. Spain shares lower at close of trade; IBEX 35 down 0.67% - Investing.com India\n",
            "   Sentiment: negative (0.97)\n",
            "   Sentiment value: -0.9703910946846008\n",
            "4. Spain shares lower at close of trade; IBEX 35 down 0.67% - Investing.com UK\n",
            "   Sentiment: negative (0.97)\n",
            "   Sentiment value: -0.9708607792854309\n"
          ]
        }
      ],
      "source": [
        "LABEL_TO_NUM = {\"positive\": 1, \"neutral\": 0, \"negative\": -1}\n",
        "\n",
        "for item in items:\n",
        "    label = item.get(\"sentiment\")\n",
        "    score = item.get(\"sentiment_score\")\n",
        "    if label is None or score is None:\n",
        "        item[\"sentiment_value\"] = None\n",
        "    else:\n",
        "        item[\"sentiment_value\"] = LABEL_TO_NUM[label] * score\n",
        "\n",
        "for i, it in enumerate(items, 1):\n",
        "    print(f\"{i}. {it['title']}\")\n",
        "    print(\"   Sentiment:\", it.get(\"sentiment\"), f\"({it.get('sentiment_score'):.2f})\")\n",
        "    print(\"   Sentiment value:\", it.get(\"sentiment_value\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fecff72-c492-470c-8b4c-c2e4e04d4d69",
      "metadata": {
        "id": "5fecff72-c492-470c-8b4c-c2e4e04d4d69"
      },
      "source": [
        "### Agregaci√≥n diaria del sentimiento de mercado\n",
        "\n",
        "En esta celda se construye un `DataFrame` de `pandas` con la informaci√≥n de sentimiento y se realiza una agregaci√≥n temporal:\n",
        "\n",
        "1. Se seleccionan columnas clave: `published_local`, `title`, `sentiment`, `sentiment_score`, `sentiment_value`.\n",
        "2. Se extrae la fecha (sin hora) en una nueva columna `date`.\n",
        "3. Se calcula, para cada d√≠a, la **media del `sentiment_value`**.\n",
        "\n",
        "El resultado es una serie temporal diaria de sentimiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6216954e-288e-465c-9d76-88322125b0b8",
      "metadata": {
        "id": "6216954e-288e-465c-9d76-88322125b0b8",
        "outputId": "1176e6db-bf85-45e8-c5d5-0c37bcf8dcb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         date  sentiment_value\n",
            "0  2026-01-23        -0.969896\n",
            "1  2026-01-24         0.832621\n"
          ]
        }
      ],
      "source": [
        "values = [it.get(\"sentiment_value\") for it in items]\n",
        "#values\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(items)\n",
        "df_small = df[[\"published_local\", \"title\", \"sentiment\", \"sentiment_score\", \"sentiment_value\"]].copy()\n",
        "df_small[\"date\"] = pd.to_datetime(df_small[\"published_local\"]).dt.date\n",
        "\n",
        "daily = df_small.groupby(\"date\")[\"sentiment_value\"].mean().reset_index()\n",
        "print(daily)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25cfd7d0-8404-4393-b04c-f5fe663d03ce",
      "metadata": {
        "id": "25cfd7d0-8404-4393-b04c-f5fe663d03ce"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "NLP-News-2",
      "language": "python",
      "name": "nlp-news"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}